---
title: "Coursera Data Science Specialization"
subtitle: "06 Statistical Inference"
author: "Georg Maubach"
date: "4 June 2017"
output:
  html_document: default
  html_notebook: default
---

# Week 01
## Module 01 Introduction
### Introduction Video

- Formal statistical inference ^[Schlussfolgerung] is: "Generating conclusions about a population from a noisy sample.".  
- Without statistical inference, we're simply living within our data. With statistical inference, we're trying to generate new knowledge. We're trying to extend beyond our data to a population to give answers. With statistical inference, our estimators have actual things that they're estimating.  
- Subject of the course is "frequency style statistical inference". We want to infer facts about a population using noisy statistical data where uncertainty must be accounted for.
- There a difficulties of trying to use data to create general conclusions about a population:
    - Is the sample representative of the population that we would like to draw inferences about?
    - Are there known and observed, known and unobserved or unknown and unobserved variables that contaminate our conclusions?
    - Is there systematic bias ^[Verzerrung] created by missing data or the design or conduct of the study?
    - What randomness exists in the data and how do we use or adjust for it? Here randomness can either by explicit via randomization or random sampling, or implicit as the aggregation of many complex unknown processes.
    - Are we trying to estimate an underlying mechanistic model of phenomena under study?

[Transcrpt](./transcripts/week-01_mod-01_chap-01_introduction_transcript.txt)  
[Supplement](./supplements/week-01_mod-01_chap-01_Introduction_Supplement.pdf)  

### Course Materials  

- [Data Science Specialization on git](https://github.com/bcaffo/courses/tree/master/06_StatisticalInference)
- [Course Material on git](https://github.com/DataScienceSpecialization/courses/tree/master/06_StatisticalInference)

Clone the directory using:

    - git clone https://github.com/bcaffo/courses.git or  
    - git clone git@github.com:bcaffo/courses.git  

- [Youtube](https://www.youtube.com/playlist?list=PLpl-gQkQivXiBmGyzLrUjzsblmQsLtkzJ)

- [Course Book Buy](https://leanpub.com/LittleInferenceBook)
- [Course Book Online](https://leanpub.com/LittleInferenceBook/read)
- [Course Book github](https://github.com/bcaffo/LittleInferenceBook)
- [Course Book leanpub](https://leanpub.com/LittleInferenceBook) (on purchase, all updates free, including homework)

- Twitter: Brian Caffo: (@bcaffo), Roger Peng (@rdpeng), Jeff Leek (@jtleek), The Department of Biostat (@jhubiostat).

- [Learning Community](http://datasciencespecialization.github.io/)
- [Community Contributing](https://github.com/DataScienceSpecialization/DataScienceSpecialization.github.io#contributing)

### Quizzes
Quizzes cover different parts of the course:

- Quiz 1 covers lectures 1 - 4
- Quiz 2 covers lectures 5 - 7
- Quiz 3 covers lectures 8 - 10
- Quiz 4 covers lectures 8 - 13

Quiz 3 and 4 cover a lot of overlapping material.

### Homework

**Remark:** The sequence within the course might be different, please see course book!

- http://bcaffo.github.io/courses/06_StatisticalInference/homework/hw1.html#1
- http://bcaffo.github.io/courses/06_StatisticalInference/homework/hw2.html#1
- http://bcaffo.github.io/courses/06_StatisticalInference/homework/hw3.html#1
- http://bcaffo.github.io/courses/06_StatisticalInference/homework/hw4.html#1

## Module 2 Probability

In this module we discuss probability, the foundation of statistical analysis. Probability assigns a number between 0 and 1 to events to give a sense of the "chance" of the event. Probability has become our default model for apparently random phenomena. Our eventual goal is to use probability models, our formal mechanism for connecting our data to a population. However, before we get to probability models, we need to understand the basics of probability calculus. The next few lectures cover these basics.

### Further Reading

- More complete treatment of the topic in class "Mathematical Biostatistics Boot Camp 1" at: 

    - https://www.youtube.com/watch?v=jkUqDVtpKs4&list=PLpl-gQkQivXhk6qSyiNj51qamjAtZISJ-
    - https://www.coursera.org/learn/biostatistics
    -https://github.com/bcaffo/Caffo-Coursera
    
### Video 1 Introduction to probability

- In an random number experiment a probality measure is a population that summarizes the randomness.
-  When we talk about probability, we're not talking about something that is in the data that we have, but as a conceptual thing that exists in the population that we would like to estimate.  
- The probability takes a possible outcome of the experiment and assigns it a number between 0 and 1.  
- Probability must follow these rules:
    - The probability that nothing occurs is 0.
    - The probablity that something occurs is 1.
    - The probability of something is 1 minus the probability that the opposite occurs.
    - The probability of at least one of two (or more) things that can not simultaneously occur (= mutually exclusive) is the sum of their respective probablities.
    - If an event A implies on the occurance of event B, then the probability of A occuring is less than the probability that B occurs.
    - For any two events the probability that at least one occurs is the sum of their probabilities minus their intersection.  

### Video 2 Probability Mass Function (PMF)

#### Introduction

- Probability calculus is useful for understanding rules that probabilities must follow.  
- However we need ways to model and think about probabilities for numeric outcomes of experiments.  
- Density and mass functions for random variables are the best starting point for this.  
- **Please note:**  Everything we are talking about up to this point is a population quantity not a statement of what occurs in the data.  
- In the course we use the data to estimate properties of the population.  

#### Random Variable

- A random variable is a numeric outcome of an experiment.
- Random variables come in two varieties: discrete and continuous:
    - discrete variables:
        - used only for a countable number of possibilities
        - we talk about the possibility that they take specific values
        - these values do not need to be numeric but it is possible to assign numeric values to it, e. g. hair color, e. g. 1 = brown, 2 = blond, 3 = black and so on
    - continous variables:
        - can take any value in a continuum (or a subset of it)
        - we talk about the probability that they lay within some range.
- Working with discrete and continuous variables:  
    - discrete variables: we assign a value to every value that they can take
    - continuous variables: we assign values to ranges that they can take

#### Examples for Random Variables  

- Discrete variables:  
    - The outcome of a flip of a coin can take only head or tail, coded as 1 = head and 2 = tail or 1 = tail and 2 = head.  
    - The outcome of the roll of a die can take only one of six possible values, best coded as 1, 2, 3, 4, 5, 6.  
    - The web traffic of a given day. The web hits can be counted. We treat it as discrete. We do not know however what the upper bound is. Thus it is a special kind of a discrete variable. We use the Poisson distribution to model this.  
    - Hypertension ^[Bluthochdruck] can take "has hypertension" and "has no hypertension". This can be coded as 0/1.
- Continuous variables:
    - The BMI is a continuous random variable with a baseline measurement.  
    - Intelligence quotients are often modeled as continuous.  

#### Probability MASS Function (PMF)  

- We work with discrete random variables by assigning a value to every possible outcome that they can take.  
- We assign the discrete random variable a function, the **Probability Mass Function**.  
- The Probability Mass Function (PMF) that takes any value a discrete random variable can take and assigns the probability that it takes that specific value.  
- A probability mass function evaluated at a value corresponds to the probability that the random variable takes that value.  
- To be valid PMF a function "p" must satisfy the same rules we defined at the beginning of the class:
    - It must be equal to or langer than "0".
    - The sum of possible values adds up to 1.
- Example: For the roll of a die we assign 1/6 for the value one, 1/6 for the value two, 1/6 for the value 3 and so on. The probability of all possible outcomes must add up to one which it actually does.  

#### Example for the Probability Mass Function (PMF)  

# %TODO%
# Weiter bei 5:18 Minuten

#### Probability Density Function (PDF)  

- The probability density function is a function that is associated with a continuous variable.  
- Areas under the PDF correspond to the probabilities for that random variable.  
- A valid PDF must satisfy:
    - It must be equal to or larger than "0" everywhere.
    - The total area under it must be one.

### Cumulative Distribution Function (CDF) and Survival Function (SF)  

Certain areas are so useful that we give them names:

1. The **Cumulative Distribution Function (CDF)** of a random variable "X" (discrete or continuous) returns the probability that the random variable is less than or equal to the value x:

   $F(x) = P(X <= x)$   # with P = probability

2. The **Survival Function (SF)** of a random variable "X" is defined as the probability that the random variable is greater than the value x:

  $S(x) = P(X >= x)$   # with P = probability

3. Notice that:

  $S(x) = 1 - F(x)$


### Qunatiles

- Quantiles are sample quantities. Here we define their population analogs.

#### Definition Quantile

- The $a{th}$ **quantile** of distribution with distribution function $F$ is a point $x_\alpha$ so that $F(x_\alpha) = \alpha$.  

#### Definition Percentile

- A **percentile** is simply a quantile with $\alpha$ expressed as a percent.

#### Definition Median

- The **median** is the $50^{th}$ percentile.

#### Exammple

The $95°{th}$ percentile of a distribution is the point so that:

1. The probability that a random variable drawn from the population is less is 95 %.
2. The probability that a random variable drawn from the population is more is 5 %.

#### Quantiles in R

R can approximate quantiles for you for common distributions:

```{r}
# qbeta(p, shape1, shape2, ncp = 0, lower.tail = TRUE, log.p = FALSE)
# p = vector of probabilities
# shape1, shape2 = non-negative parameters of the Beta distribution
qbeta(0.5, 2, 1)
```

### Summary

- You might be wondering at this point "I have heard of the median before, it did not require integratin. Where is the data?".  
- We are referring to **population quantities**. Therefore, the median being discussed is the population median.  
- A probability model connects the data to the population using assumptions.  
- Therefore, the median we are discussing is the **estimand** ^[Schätzung], the sample median will be the **estimator** ^[Schätzwert].  

